"""
ì œì¡° í˜„ì¥ ë°ì´í„° ë¶„ì„ Multi-Agent ì‹œìŠ¤í…œ
Hugging Face Hub + LangChain ê¸°ë°˜
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import json

# LangChain imports
from langgraph.prebuilt import create_react_agent
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint

# Hugging Face ì„¤ì •
import os
from dotenv import load_dotenv

load_dotenv()
api_token = os.getenv("HUGGINGFACE_API_KEY")

class ManufacturingDataAnalyzer:
    """ì œì¡° ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, production_data: pd.DataFrame, qualitative_data: Dict):
        self.production_df = production_data
        self.qualitative_data = qualitative_data
        
    def get_summary_stats(self) -> Dict:
        """ìƒì‚° ë°ì´í„° ìš”ì•½ í†µê³„"""
        return {
            "total_orders": len(self.production_df),
            "completed_orders": len(self.production_df[self.production_df['order_status'] == 'completed']),
            "avg_defect_rate": (self.production_df['defect_quantity'] / 
                               self.production_df['actual_quantity']).mean() * 100,
            "lines": self.production_df['line_id'].unique().tolist(),
            "products": self.production_df['product_id'].unique().tolist()
        }
    
    def get_defect_analysis(self, line_id: Optional[str] = None) -> Dict:
        """ë¶ˆëŸ‰ë¥  ë¶„ì„"""
        df = self.production_df[self.production_df['order_status'] == 'completed'].copy()
        if line_id:
            df = df[df['line_id'] == line_id]
        
        df['defect_rate'] = (df['defect_quantity'] / df['actual_quantity']) * 100
        
        return {
            "average_defect_rate": df['defect_rate'].mean(),
            "max_defect_rate": df['defect_rate'].max(),
            "by_line": df.groupby('line_id')['defect_rate'].mean().to_dict(),
            "by_product": df.groupby('product_id')['defect_rate'].mean().to_dict(),
            "by_shift": df.groupby('shift')['defect_rate'].mean().to_dict()
        }
    
    def get_production_efficiency(self) -> Dict:
        """ìƒì‚° íš¨ìœ¨ ë¶„ì„"""
        df = self.production_df[self.production_df['order_status'] == 'completed'].copy()
        df['achievement_rate'] = (df['actual_quantity'] / df['target_quantity']) * 100
        
        return {
            "avg_achievement_rate": df['achievement_rate'].mean(),
            "by_line": df.groupby('line_id')['achievement_rate'].mean().to_dict(),
            "underperforming_orders": len(df[df['achievement_rate'] < 90])
        }
    
    def find_correlations(self, threshold: float = 0.3) -> Dict:
        """ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        df = self.production_df[self.production_df['order_status'] == 'completed'].copy()
        df['defect_rate'] = (df['defect_quantity'] / df['actual_quantity']) * 100
        df['achievement_rate'] = (df['actual_quantity'] / df['target_quantity']) * 100
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = ['actual_quantity', 'defect_quantity', 'target_quantity', 
                       'defect_rate', 'achievement_rate']
        corr_matrix = df[numeric_cols].corr()
        
        # ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
        high_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                if abs(corr_matrix.iloc[i, j]) > threshold:
                    high_corr.append({
                        "var1": corr_matrix.columns[i],
                        "var2": corr_matrix.columns[j],
                        "correlation": corr_matrix.iloc[i, j]
                    })
        
        return {"high_correlations": high_corr}
    
    def get_rag_context(self, anomaly_type: str) -> List[Dict]:
        """ì •ì„± ë°ì´í„°ì—ì„œ ê´€ë ¨ ë§¥ë½ ê²€ìƒ‰ (RAG)"""
        relevant_docs = []
        
        # ì‘ì—… ì¼ë³´ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        for log in self.qualitative_data.get('work_logs', []):
            if any(tag in log.get('tags', []) for tag in 
                   ['ìƒì‚°ëŸ‰ê°ì†Œ', 'í’ˆì§ˆì´ìƒ', 'ë¶ˆëŸ‰ë¥ ì¦ê°€', 'ì„¤ë¹„ì´ìƒ']):
                relevant_docs.append({
                    "type": "work_log",
                    "content": log['content'],
                    "date": log['date'],
                    "line": log['line']
                })
        
        # ì •ë¹„ ë¡œê·¸ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        for log in self.qualitative_data.get('maintenance_logs', []):
            relevant_docs.append({
                "type": "maintenance_log",
                "content": log['content'],
                "date": log['date'],
                "equipment": log['equipment']
            })
        
        return relevant_docs[:5]  # ìµœê·¼ 5ê°œë§Œ ë°˜í™˜


def create_llm():
    """ê³µí†µ LLM ìƒì„± í•¨ìˆ˜"""
    endpoint = HuggingFaceEndpoint(
        repo_id="mistralai/Mistral-7B-Instruct-v0.2",
        huggingfacehub_api_token=api_token,
        temperature=0.5,
        max_new_tokens=1024,
    )
    return ChatHuggingFace(llm=endpoint)


class DescriptiveAgent:
    """ì„¤ëª… ì—ì´ì „íŠ¸: í˜„í™© íŒŒì•… ë° ë°ì´í„° ìš”ì•½"""
    
    def __init__(self, analyzer: ManufacturingDataAnalyzer):
        self.analyzer = analyzer
        self.llm = create_llm()
        
    def analyze(self) -> str:
        """í˜„í™© ë¶„ì„ ìˆ˜í–‰"""
        stats = self.analyzer.get_summary_stats()
        defects = self.analyzer.get_defect_analysis()
        efficiency = self.analyzer.get_production_efficiency()
        
        prompt = f"""ë‹¹ì‹ ì€ ì œì¡° í˜„ì¥ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìƒì‚° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í˜„í™©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.**

ì „ì²´ í†µê³„:
- ì´ ì£¼ë¬¸ ìˆ˜: {stats['total_orders']}
- ì™„ë£Œëœ ì£¼ë¬¸: {stats['completed_orders']}
- í‰ê·  ë¶ˆëŸ‰ë¥ : {stats['avg_defect_rate']:.2f}%
- ìƒì‚° ë¼ì¸: {', '.join(stats['lines'])}

ë¶ˆëŸ‰ ë¶„ì„:
- ì „ì²´ í‰ê·  ë¶ˆëŸ‰ë¥ : {defects['average_defect_rate']:.2f}%
- ìµœëŒ€ ë¶ˆëŸ‰ë¥ : {defects['max_defect_rate']:.2f}%
- ë¼ì¸ë³„ ë¶ˆëŸ‰ë¥ : {json.dumps(defects['by_line'], ensure_ascii=False)}
- êµëŒ€ì¡°ë³„ ë¶ˆëŸ‰ë¥ : {json.dumps(defects['by_shift'], ensure_ascii=False)}

ìƒì‚° íš¨ìœ¨:
- í‰ê·  ëª©í‘œ ë‹¬ì„±ë¥ : {efficiency['avg_achievement_rate']:.2f}%
- ì €ì„±ê³¼ ì£¼ë¬¸ ìˆ˜: {efficiency['underperforming_orders']}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
1. ì „ì²´ì ì¸ ìƒì‚° í˜„í™© ìš”ì•½
2. ì£¼ìš” ë¬¸ì œì  ì‹ë³„
3. ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ ì§€ì 

ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        response = self.llm.invoke(prompt)
        # ChatHuggingFaceëŠ” ë©”ì‹œì§€ ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ content ì¶”ì¶œ
        return response.content if hasattr(response, 'content') else str(response)


class DiagnosticAgent:
    """ì§„ë‹¨ ì—ì´ì „íŠ¸: ë¬¸ì œ ì›ì¸ ë¶„ì„ (RCA)"""
    
    def __init__(self, analyzer: ManufacturingDataAnalyzer):
        self.analyzer = analyzer
        self.llm = create_llm()
        
    def analyze(self) -> str:
        """ê·¼ë³¸ ì›ì¸ ë¶„ì„"""
        correlations = self.analyzer.find_correlations()
        defects = self.analyzer.get_defect_analysis()
        rag_context = self.analyzer.get_rag_context("defect")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        context_str = "\n".join([
            f"[{doc['type']}] {doc['date']}: {doc['content'][:200]}..." 
            for doc in rag_context
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ ì œì¡° í˜„ì¥ì˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„(RCA) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.**

ì •ëŸ‰ ë°ì´í„° ë¶„ì„:
- ë¼ì¸ë³„ ë¶ˆëŸ‰ë¥ : {json.dumps(defects['by_line'], ensure_ascii=False)}
- ì œí’ˆë³„ ë¶ˆëŸ‰ë¥ : {json.dumps(defects['by_product'], ensure_ascii=False)}
- êµëŒ€ì¡°ë³„ ë¶ˆëŸ‰ë¥ : {json.dumps(defects['by_shift'], ensure_ascii=False)}
- ì£¼ìš” ìƒê´€ê´€ê³„: {json.dumps(correlations['high_correlations'][:3], ensure_ascii=False)}

ì •ì„± ë°ì´í„° (ì‘ì—… ì¼ì§€ ë° ì •ë¹„ ë¡œê·¸):
{context_str}

ìœ„ ì •ëŸ‰/ì •ì„± ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬:
1. ë¶ˆëŸ‰ë¥ ì´ ë†’ì€ ì£¼ìš” ì›ì¸ 3ê°€ì§€ ë„ì¶œ
2. ê° ì›ì¸ì— ëŒ€í•œ ê·¼ê±° ì œì‹œ (ë°ì´í„° ê¸°ë°˜)
3. ë¼ì¸ë³„/ì œí’ˆë³„ íŠ¹ì´ì‚¬í•­ ë¶„ì„
4. êµëŒ€ì¡°ë³„ ì°¨ì´ê°€ ë‚˜ëŠ” ì´ìœ  ì¶”ë¡ 

ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ë©° í•œêµ­ì–´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."""

        response = self.llm.invoke(prompt)
        return response.content if hasattr(response, 'content') else str(response)


class PredictiveAgent:
    """ì˜ˆì¸¡ ì—ì´ì „íŠ¸: ë¯¸ë˜ ì˜ˆì¸¡"""
    
    def __init__(self, analyzer: ManufacturingDataAnalyzer):
        self.analyzer = analyzer
        self.llm = create_llm()
        
    def predict_defects(self) -> Dict:
        """ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡"""
        df = self.analyzer.production_df[
            self.analyzer.production_df['order_status'] == 'completed'
        ].copy()
        df['defect_rate'] = (df['defect_quantity'] / df['actual_quantity']) * 100
        
        # ê°„ë‹¨í•œ ì´ë™í‰ê·  ê¸°ë°˜ ì˜ˆì¸¡
        recent_data = df.tail(100)
        predictions = {}
        
        for line in df['line_id'].unique():
            line_data = recent_data[recent_data['line_id'] == line]
            if len(line_data) > 0:
                trend = line_data['defect_rate'].rolling(window=10).mean().iloc[-1]
                predictions[line] = {
                    "predicted_defect_rate": trend,
                    "risk_level": "ë†’ìŒ" if trend > 4 else "ì¤‘ê°„" if trend > 2 else "ë‚®ìŒ"
                }
        
        return predictions
    
    def analyze(self) -> str:
        """ì˜ˆì¸¡ ë¶„ì„ ìˆ˜í–‰"""
        predictions = self.predict_defects()
        efficiency = self.analyzer.get_production_efficiency()
        
        prompt = f"""ë‹¹ì‹ ì€ ì œì¡° í˜„ì¥ì˜ ì˜ˆì¸¡ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.**

ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡:
- ë¼ì¸ë³„ ì˜ˆì¸¡ ë¶ˆëŸ‰ë¥ : {json.dumps(predictions, ensure_ascii=False)}
- í˜„ì¬ í‰ê·  ëª©í‘œ ë‹¬ì„±ë¥ : {efficiency['avg_achievement_rate']:.2f}%

ë‹¤ìŒ ì‚¬í•­ì„ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”:
1. í–¥í›„ 1ì£¼ì¼ê°„ ê° ë¼ì¸ì˜ ë¶ˆëŸ‰ë¥  ì¶”ì„¸
2. ì„¤ë¹„ ê³ ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¼ì¸ ì‹ë³„
3. ìƒì‚° ëª©í‘œ ë¯¸ë‹¬ì„± ìœ„í—˜ì´ ìˆëŠ” ì œí’ˆ/ë¼ì¸
4. ì¬ê³  ìµœì í™”ë¥¼ ìœ„í•œ ìƒì‚°ëŸ‰ ì¡°ì • í•„ìš” ì—¬ë¶€

ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì˜ˆì¸¡ì„ í•œêµ­ì–´ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”."""

        response = self.llm.invoke(prompt)
        return response.content if hasattr(response, 'content') else str(response)


class PrescriptiveAgent:
    """ì²˜ë°© ì—ì´ì „íŠ¸: ìµœì  í–‰ë™ ì œì‹œ"""
    
    def __init__(self, analyzer: ManufacturingDataAnalyzer):
        self.analyzer = analyzer
        self.llm = create_llm()
        
    def analyze(self, diagnostic_result: str, predictive_result: str) -> str:
        """ì²˜ë°© ë¶„ì„ ìˆ˜í–‰"""
        defects = self.analyzer.get_defect_analysis()
        efficiency = self.analyzer.get_production_efficiency()
        
        prompt = f"""ë‹¹ì‹ ì€ ì œì¡° í˜„ì¥ì˜ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.**

ì§„ë‹¨ ê²°ê³¼:
{diagnostic_result}

ì˜ˆì¸¡ ê²°ê³¼:
{predictive_result}

í˜„ì¬ ìƒíƒœ:
- í‰ê·  ë¶ˆëŸ‰ë¥ : {defects['average_defect_rate']:.2f}%
- í‰ê·  ëª©í‘œ ë‹¬ì„±ë¥ : {efficiency['avg_achievement_rate']:.2f}%
- ì €ì„±ê³¼ ì£¼ë¬¸: {efficiency['underperforming_orders']}ê±´

ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ìµœì í™” ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”:

1. ê³µì • ìµœì í™”:
   - ê° ë¼ì¸ë³„ ìµœì  ì„¤ì •ê°’ ì œì•ˆ
   - ë¶ˆëŸ‰ë¥  ê°ì†Œë¥¼ ìœ„í•œ êµ¬ì²´ì  ì¡°ì¹˜
   
2. ìŠ¤ì¼€ì¤„ë§ ìµœì í™”:
   - êµëŒ€ì¡°ë³„ ì‘ì—… ë°°ë¶„ ê°œì„ ì•ˆ
   - ì œí’ˆë³„ ìƒì‚° ìˆœì„œ ì¡°ì • ì œì•ˆ
   
3. ìì› ë°°ë¶„:
   - ì •ë¹„ ìš°ì„ ìˆœìœ„ ì„¤ì •
   - ì¸ë ¥ ì¬ë°°ì¹˜ í•„ìš” ì—¬ë¶€
   
4. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ (ìš°ì„ ìˆœìœ„ ìˆœ):

ê° ì œì•ˆì— ëŒ€í•´ ì˜ˆìƒ íš¨ê³¼ì™€ ì‹¤í–‰ ë°©ë²•ì„ í•œêµ­ì–´ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”."""

        response = self.llm.invoke(prompt)
        return response.content if hasattr(response, 'content') else str(response)


class ManufacturingAgentOrchestrator:
    """Multi-Agent ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self, production_csv_path: str, qualitative_json_path: str):
        # ë°ì´í„° ë¡œë“œ
        self.production_df = pd.read_csv(production_csv_path)
        
        with open(qualitative_json_path, 'r', encoding='utf-8') as f:
            self.qualitative_data = json.load(f)
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.analyzer = ManufacturingDataAnalyzer(
            self.production_df, 
            self.qualitative_data
        )
        
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.descriptive_agent = DescriptiveAgent(self.analyzer)
        self.diagnostic_agent = DiagnosticAgent(self.analyzer)
        self.predictive_agent = PredictiveAgent(self.analyzer)
        self.prescriptive_agent = PrescriptiveAgent(self.analyzer)
        
    def run_analysis(self) -> Dict[str, str]:
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        print("=" * 80)
        print("ì œì¡° í˜„ì¥ AI ì—ì´ì „íŠ¸ ë¶„ì„ ì‹œì‘")
        print("=" * 80)
        
        # 1. ì„¤ëª… ì—ì´ì „íŠ¸
        print("\n[1/4] ì„¤ëª… ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
        descriptive_result = self.descriptive_agent.analyze()
        print("âœ“ ì™„ë£Œ")
        
        # 2. ì§„ë‹¨ ì—ì´ì „íŠ¸
        print("\n[2/4] ì§„ë‹¨ ì—ì´ì „íŠ¸ (RCA) ì‹¤í–‰ ì¤‘...")
        diagnostic_result = self.diagnostic_agent.analyze()
        print("âœ“ ì™„ë£Œ")
        
        # 3. ì˜ˆì¸¡ ì—ì´ì „íŠ¸
        print("\n[3/4] ì˜ˆì¸¡ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
        predictive_result = self.predictive_agent.analyze()
        print("âœ“ ì™„ë£Œ")
        
        # 4. ì²˜ë°© ì—ì´ì „íŠ¸
        print("\n[4/4] ì²˜ë°© ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
        prescriptive_result = self.prescriptive_agent.analyze(
            diagnostic_result, 
            predictive_result
        )
        print("âœ“ ì™„ë£Œ")
        
        results = {
            "descriptive": descriptive_result,
            "diagnostic": diagnostic_result,
            "predictive": predictive_result,
            "prescriptive": prescriptive_result
        }
        
        return results
    
    def print_results(self, results: Dict[str, str]):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        
        print("\nğŸ“Š 1. í˜„í™© ë¶„ì„ (ì„¤ëª… ì—ì´ì „íŠ¸)")
        print("-" * 80)
        print(results['descriptive'])
        
        print("\nğŸ” 2. ê·¼ë³¸ ì›ì¸ ë¶„ì„ (ì§„ë‹¨ ì—ì´ì „íŠ¸)")
        print("-" * 80)
        print(results['diagnostic'])
        
        print("\nğŸ“ˆ 3. ë¯¸ë˜ ì˜ˆì¸¡ (ì˜ˆì¸¡ ì—ì´ì „íŠ¸)")
        print("-" * 80)
        print(results['predictive'])
        
        print("\nğŸ’¡ 4. ìµœì í™” ë°©ì•ˆ (ì²˜ë°© ì—ì´ì „íŠ¸)")
        print("-" * 80)
        print(results['prescriptive'])


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
    orchestrator = ManufacturingAgentOrchestrator(
        production_csv_path="input/sample_querydata/production_orders.csv",
        qualitative_json_path="input/RAG/qualitative_log.json"
    )
    
    # ë¶„ì„ ì‹¤í–‰
    results = orchestrator.run_analysis()
    
    # ê²°ê³¼ ì¶œë ¥
    orchestrator.print_results(results)
    
    # ê²°ê³¼ ì €ì¥
    output_dir = 'output'
    os.makedirs(output_dir, exist_ok=True)
    
    with open('output/analysis_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ 'analysis_results.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")