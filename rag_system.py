"""
ì œì¡°ì—… RAG ì‹œìŠ¤í…œ
- RAG1: DB ìŠ¤í‚¤ë§ˆ ì •ë³´
- RAG2: KPI ê³µì‹ ì •ë³´  
- RAG3: Golden SQL ì¿¼ë¦¬
"""

import json
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import re
import io
import sys

# í‘œì¤€ ì¶œë ¥(stdout)ì„ UTF-8ë¡œ ì¸ì½”ë”©í•˜ë„ë¡ ì¬ì„¤ì •
if sys.platform == "win32":
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8', line_buffering=True)
        sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8', line_buffering=True)
    except:
        pass

@dataclass
class Document:
    """RAG ë¬¸ì„œ í´ë˜ìŠ¤"""
    doc_id: str
    content: str
    metadata: Dict
    embedding: Optional[np.ndarray] = None


class SimpleEmbedding:
    """
    ê°„ë‹¨í•œ TF-IDF ê¸°ë°˜ ì„ë² ë”© (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” sentence-transformers ë“± ì‚¬ìš©)
    """
    def __init__(self):
        self.vocab = {}
        self.idf = {}
        self.vocab_size = 0
        
    def _tokenize(self, text: str) -> List[str]:
        """í•œê¸€/ì˜ë¬¸ í† í°í™”"""
        # ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
        text = text.lower()
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
        tokens = re.findall(r'[ê°€-í£]+|[a-z]+|[0-9]+', text)
        return tokens
    
    def fit(self, documents: List[str]):
        """ì–´íœ˜ ì‚¬ì „ ë° IDF ê³„ì‚°"""
        # ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•
        all_tokens = set()
        doc_freq = {}
        
        for doc in documents:
            tokens = set(self._tokenize(doc))
            all_tokens.update(tokens)
            for token in tokens:
                doc_freq[token] = doc_freq.get(token, 0) + 1
        
        # ì–´íœ˜ ì¸ë±ìŠ¤ ìƒì„±
        self.vocab = {token: idx for idx, token in enumerate(sorted(all_tokens))}
        self.vocab_size = len(self.vocab)
        
        # IDF ê³„ì‚°
        n_docs = len(documents)
        for token, freq in doc_freq.items():
            self.idf[token] = np.log((n_docs + 1) / (freq + 1)) + 1
            
    def transform(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (TF-IDF)"""
        tokens = self._tokenize(text)
        vector = np.zeros(self.vocab_size)
        
        # TF ê³„ì‚°
        tf = {}
        for token in tokens:
            tf[token] = tf.get(token, 0) + 1
        
        # TF-IDF ë²¡í„° ìƒì„±
        for token, count in tf.items():
            if token in self.vocab:
                idx = self.vocab[token]
                vector[idx] = count * self.idf.get(token, 1)
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = vector / norm
            
        return vector


class RAGSystem:
    """RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str):
        self.name = name
        self.documents: List[Document] = []
        self.embedder = SimpleEmbedding()
        
    def add_document(self, doc_id: str, content: str, metadata: Dict):
        """ë¬¸ì„œ ì¶”ê°€"""
        doc = Document(doc_id=doc_id, content=content, metadata=metadata)
        self.documents.append(doc)
        
    def build_index(self):
        """ì„ë² ë”© ì¸ë±ìŠ¤ êµ¬ì¶•"""
        # ëª¨ë“  ë¬¸ì„œ ë‚´ìš©ìœ¼ë¡œ ì–´íœ˜ í•™ìŠµ
        contents = [doc.content for doc in self.documents]
        self.embedder.fit(contents)
        
        # ê° ë¬¸ì„œ ì„ë² ë”©
        for doc in self.documents:
            doc.embedding = self.embedder.transform(doc.content)
            
        print(f"[{self.name}] ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.documents)}ê°œ ë¬¸ì„œ, ì–´íœ˜ í¬ê¸°: {self.embedder.vocab_size}")
        
    def search(self, query: str, top_k: int = 3) -> List[Tuple[Document, float]]:
        """ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰"""
        query_embedding = self.embedder.transform(query)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        for doc in self.documents:
            if doc.embedding is not None:
                similarity = np.dot(query_embedding, doc.embedding)
                results.append((doc, similarity))
        
        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]


class ManufacturingRAGSystem:
    """ì œì¡°ì—… í†µí•© RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.rag1_schema = RAGSystem("RAG1-Schema")
        self.rag2_kpi = RAGSystem("RAG2-KPI")
        self.rag3_golden_sql = RAGSystem("RAG3-GoldenSQL")
        
    def load_schema_data(self, filepath: str):
        """ìŠ¤í‚¤ë§ˆ ë°ì´í„° ë¡œë“œ (RAG1)"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for table in data['tables']:
            # í…Œì´ë¸” ì •ë³´ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            columns_text = ", ".join([
                f"{col['name']}({col['type']}): {col['description']}" 
                for col in table['columns']
            ])
            
            content = f"""
            í…Œì´ë¸”ëª…: {table['table_name']}
            ìŠ¤í‚¤ë§ˆ: {table['schema']}
            ì„¤ëª…: {table['description']}
            ì»¬ëŸ¼: {columns_text}
            ê´€ê³„: {', '.join(table.get('relationships', []))}
            """
            
            self.rag1_schema.add_document(
                doc_id=f"schema_{table['table_name']}",
                content=content,
                metadata={
                    "table_name": table['table_name'],
                    "schema": table['schema'],
                    "columns": table['columns'],
                    "type": "schema"
                }
            )
        
        self.rag1_schema.build_index()
        print(f"ìŠ¤í‚¤ë§ˆ RAG ë¡œë“œ ì™„ë£Œ: {len(data['tables'])}ê°œ í…Œì´ë¸”")
        
    def load_kpi_data(self, filepath: str):
        """KPI ë°ì´í„° ë¡œë“œ (RAG2)"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for kpi in data['kpis']:
            # KPI ì •ë³´ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            sub_formulas = ""
            if 'sub_formulas' in kpi:
                sub_formulas = " / ".join([f"{k}: {v}" for k, v in kpi['sub_formulas'].items()])
            
            content = f"""
            KPIëª…: {kpi['kpi_name']} ({kpi['kpi_name_kr']})
            ì¹´í…Œê³ ë¦¬: {kpi['category']}
            ì„¤ëª…: {kpi['description']}
            ê³µì‹: {kpi['formula']}
            ì„¸ë¶€ê³µì‹: {sub_formulas}
            ë‹¨ìœ„: {kpi['unit']}
            ëª©í‘œê°’: {kpi['target_value']}
            ê´€ë ¨í…Œì´ë¸”: {', '.join(kpi['related_tables'])}
            í•´ì„: {kpi.get('interpretation', '')}
            """
            
            self.rag2_kpi.add_document(
                doc_id=f"kpi_{kpi['kpi_id']}",
                content=content,
                metadata={
                    "kpi_id": kpi['kpi_id'],
                    "kpi_name": kpi['kpi_name'],
                    "kpi_name_kr": kpi['kpi_name_kr'],
                    "formula": kpi['formula'],
                    "sql_example": kpi.get('sql_example', ''),
                    "related_tables": kpi['related_tables'],
                    "type": "kpi"
                }
            )
        
        self.rag2_kpi.build_index()
        print(f"KPI RAG ë¡œë“œ ì™„ë£Œ: {len(data['kpis'])}ê°œ KPI")
        
    def load_golden_sql_data(self, filepath: str):
        """Golden SQL ë°ì´í„° ë¡œë“œ (RAG3)"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for query in data['queries']:
            content = f"""
            ìì—°ì–´: {query['natural_language']}
            í‚¤ì›Œë“œ: {', '.join(query['keywords'])}
            ì¹´í…Œê³ ë¦¬: {query['category']}
            SQL: {query['sql']}
            ì„¤ëª…: {query['explanation']}
            """
            
            self.rag3_golden_sql.add_document(
                doc_id=f"sql_{query['query_id']}",
                content=content,
                metadata={
                    "query_id": query['query_id'],
                    "natural_language": query['natural_language'],
                    "keywords": query['keywords'],
                    "sql": query['sql'],
                    "explanation": query['explanation'],
                    "type": "golden_sql"
                }
            )
        
        self.rag3_golden_sql.build_index()
        print(f"Golden SQL RAG ë¡œë“œ ì™„ë£Œ: {len(data['queries'])}ê°œ ì¿¼ë¦¬")
        
    def search_all(self, query: str, top_k: int = 3) -> Dict[str, List]:
        """ëª¨ë“  RAGì—ì„œ ê²€ìƒ‰"""
        results = {
            "schema": self.rag1_schema.search(query, top_k),
            "kpi": self.rag2_kpi.search(query, top_k),
            "golden_sql": self.rag3_golden_sql.search(query, top_k)
        }
        return results
    
    def generate_context(self, query: str, top_k: int = 3) -> str:
        """ì¿¼ë¦¬ ìƒì„±ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        results = self.search_all(query, top_k)
        
        context_parts = []
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´
        context_parts.append("=== ê´€ë ¨ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ===")
        for doc, score in results["schema"]:
            if score > 0.1:  # ì„ê³„ê°’ ì´ìƒë§Œ
                context_parts.append(f"\n[í…Œì´ë¸”: {doc.metadata['table_name']}] (ìœ ì‚¬ë„: {score:.3f})")
                context_parts.append(f"ìŠ¤í‚¤ë§ˆ: {doc.metadata['schema']}")
                context_parts.append("ì»¬ëŸ¼:")
                for col in doc.metadata['columns']:
                    pk = " (PK)" if col.get('primary_key') else ""
                    fk = f" -> {col['foreign_key']}" if col.get('foreign_key') else ""
                    context_parts.append(f"  - {col['name']} {col['type']}{pk}{fk}: {col['description']}")
        
        # KPI ì •ë³´
        context_parts.append("\n=== ê´€ë ¨ KPI ê³µì‹ ===")
        for doc, score in results["kpi"]:
            if score > 0.1:
                context_parts.append(f"\n[{doc.metadata['kpi_name_kr']}] (ìœ ì‚¬ë„: {score:.3f})")
                context_parts.append(f"ê³µì‹: {doc.metadata['formula']}")
                context_parts.append(f"ê´€ë ¨ í…Œì´ë¸”: {', '.join(doc.metadata['related_tables'])}")
                if doc.metadata.get('sql_example'):
                    context_parts.append(f"ì˜ˆì‹œ SQL:\n{doc.metadata['sql_example']}")
        
        # Golden SQL
        context_parts.append("\n=== ìœ ì‚¬ Golden SQL ===")
        for doc, score in results["golden_sql"]:
            if score > 0.1:
                context_parts.append(f"\n[{doc.metadata['query_id']}] (ìœ ì‚¬ë„: {score:.3f})")
                context_parts.append(f"ìì—°ì–´: {doc.metadata['natural_language']}")
                context_parts.append(f"SQL:\n{doc.metadata['sql']}")
                context_parts.append(f"ì„¤ëª…: {doc.metadata['explanation']}")
        
        return "\n".join(context_parts)


def demo():
    """ë°ëª¨ ì‹¤í–‰"""
    print("=" * 60)
    print("ì œì¡°ì—… RAG ì‹œìŠ¤í…œ êµ¬ì¶•")
    print("=" * 60)
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag_system = ManufacturingRAGSystem()
    
    # ë°ì´í„° ë¡œë“œ
    print("\n[1] ë°ì´í„° ë¡œë“œ ì¤‘...")
    rag_system.load_schema_data("./input/RAG/schema_Info.json")
    rag_system.load_kpi_data("./input/RAG/kpi.json")
    rag_system.load_golden_sql_data("./input/RAG/goldenSQL.json")
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì´ë²ˆ ë‹¬ ë¼ì¸ë³„ OEE í˜„í™©ì„ ë³´ì—¬ì¤˜",
        "ë¶ˆëŸ‰ë¥ ì´ ë†’ì€ ì œí’ˆ TOP 5 ì•Œë ¤ì¤˜",
        "ì„¤ë¹„ ê°€ë™ë¥ ê³¼ MTBF í˜„í™©",
        "ì¬ê³ ê°€ ë¶€ì¡±í•œ ìì¬ ëª©ë¡",
        "ì›”ë³„ ìƒì‚°ë‹¬ì„±ë¥  ì¶”ì´"
    ]
    
    print("\n" + "=" * 60)
    print("[2] RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for query in test_queries:
        print(f"\n{'â”€' * 60}")
        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: {query}")
        print('â”€' * 60)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = rag_system.generate_context(query, top_k=2)
        print(context)
        
    return rag_system


# if __name__ == "__main__":
#     rag_system = demo()